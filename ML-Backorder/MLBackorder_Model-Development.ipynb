{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operationalizing a Machine Learning Pipeline for Product Backorder - \n",
    "### Developing the Model (Part 2)\n",
    "\n",
    "In this part, we will develop three unique pipelines for predicting backorder. We'll use the smart sample from the MLBackorder_Preprocessing notebook to fit and evaluate these pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reload the previous smart sampling from local file \n",
    "# ----------------------------------\n",
    "X_sampled, y_sampled, rus = joblib.load('sampledata-Part1-V2.pkl')\n",
    "\n",
    "X = X_sampled\n",
    "y = y_sampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9964, 20)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure the Data is Normalized/standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize\n",
    "\n",
    "#from sklearn import preprocessing\n",
    "\n",
    "#processor = preprocessing.MinMaxScaler()\n",
    "#range_scaled = processor.fit_transform([X, y])\n",
    "\n",
    "#print(\"Range and Scaled converstion of x_train data\")\n",
    "#print(range_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2989, 20)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Pipeline\n",
    "\n",
    "Below I will design an operationalized machine learning pipeline, which includes:\n",
    "\n",
    "* Anomaly detection\n",
    "* Dimensionality Reduction\n",
    "* Train a model\n",
    "\n",
    "For simplicity, I'll avoid fitting an anomaly detection method within a pipeline in order to create the workflow in two steps: \n",
    "    * Step I: Fit an outlier with the training set\n",
    "    * Step II: Define a pipeline using a feature selection and a classification method. Then cross-validate the pipeline using the training data, being sure to remove the outliers. \n",
    "\n",
    "* Once we fit the pipeline, we'll identify the best model and give an unbiased evaluation using the test set that we created earlier. For unbiased evaluations, I'll report the confusion matrix, precision, recall, f1-score, and accuracy. \n",
    "\n",
    "**Note:** Below, I'll be using Grid Search to find the optimal parameters of the pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, f_regression, chi2, SelectFromModel\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline #1\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of outliers = 84\n"
     ]
    }
   ],
   "source": [
    "# Anomaly Detection\n",
    "# ----------------------------------\n",
    "iso_forest = IsolationForest(contamination = 'auto', random_state = 42)\n",
    "iso_outliers = iso_forest.fit_predict(X_train) == -1\n",
    "print(f\"Num of outliers = {np.sum(iso_outliers)}\")\n",
    "\n",
    "X_iso = X_train[~iso_outliers]\n",
    "y_iso = y_train[~iso_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensionality Reduction\n",
    "# ----------------------------------\n",
    "X_train_iso, X_test_iso, y_train_iso, y_test_iso = train_test_split(X_iso, y_iso, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2033, 20)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_iso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iso_model = LogisticRegression(solver = 'liblinear', max_iter = 10000)\n",
    "#pred_fit = iso_model.fit(X_iso, y_iso) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection and classification pipeline with grid search\n",
    "# ----------------------------------\n",
    "\n",
    "n_components = 5\n",
    "\n",
    "#pca = PCA(n_components = n_components, svd_solver = 'randomized', \n",
    "       #   whiten = True).fit(X_iso)\n",
    "#pca_fit = pca.fit(X_iso)\n",
    "\n",
    "pca = PCA(n_components = n_components)\n",
    "dtc = DecisionTreeClassifier(random_state = 0)\n",
    "\n",
    "pipe_1 = Pipeline([('PCA', pca),\n",
    "                   ('dtc', dtc)])\n",
    "\n",
    "param_grid1 = [{'PCA__n_components': [3, 5, 7, 10, 12]},\n",
    "              {'dtc__criterion': [\"gini\", \"entropy\"]}, \n",
    "              {'dtc__max_depth': [2, 4, 6, 8, 10]}]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.03528666, 0.04278698, 0.06184106, 0.05258293, 0.12212863,\n",
      "       0.05865579, 0.07750239, 0.02291837, 0.04020157, 0.00934958,\n",
      "       0.01019602, 0.0595417 ]), 'std_fit_time': array([0.03362005, 0.03846305, 0.03823092, 0.03929012, 0.02875233,\n",
      "       0.03872733, 0.0314253 , 0.0325633 , 0.03890322, 0.00011281,\n",
      "       0.00015134, 0.0389185 ]), 'mean_score_time': array([0.00064397, 0.00059438, 0.00062904, 0.03184218, 0.01613898,\n",
      "       0.00062895, 0.00062633, 0.00059133, 0.01621528, 0.00056272,\n",
      "       0.01587906, 0.0005867 ]), 'std_score_time': array([7.80154264e-05, 1.08452940e-05, 6.48180449e-05, 3.82749371e-02,\n",
      "       3.06684702e-02, 3.85271440e-05, 5.34238529e-05, 3.31192156e-05,\n",
      "       3.10850934e-02, 1.51978707e-05, 3.06549605e-02, 2.34395415e-05]), 'param_PCA__n_components': masked_array(data=[3, 5, 7, 10, 12, --, --, --, --, --, --, --],\n",
      "             mask=[False, False, False, False, False,  True,  True,  True,\n",
      "                    True,  True,  True,  True],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_dtc__criterion': masked_array(data=[--, --, --, --, --, 'gini', 'entropy', --, --, --, --,\n",
      "                   --],\n",
      "             mask=[ True,  True,  True,  True,  True, False, False,  True,\n",
      "                    True,  True,  True,  True],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_dtc__max_depth': masked_array(data=[--, --, --, --, --, --, --, 2, 4, 6, 8, 10],\n",
      "             mask=[ True,  True,  True,  True,  True,  True,  True, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'PCA__n_components': 3}, {'PCA__n_components': 5}, {'PCA__n_components': 7}, {'PCA__n_components': 10}, {'PCA__n_components': 12}, {'dtc__criterion': 'gini'}, {'dtc__criterion': 'entropy'}, {'dtc__max_depth': 2}, {'dtc__max_depth': 4}, {'dtc__max_depth': 6}, {'dtc__max_depth': 8}, {'dtc__max_depth': 10}], 'split0_test_score': array([0.88943489, 0.89189189, 0.89434889, 0.87469287, 0.87469287,\n",
      "       0.91154791, 0.87960688, 0.8992629 , 0.91400491, 0.93120393,\n",
      "       0.91646192, 0.88452088]), 'split1_test_score': array([0.91891892, 0.8992629 , 0.90663391, 0.91891892, 0.92383292,\n",
      "       0.91891892, 0.91891892, 0.91400491, 0.92628993, 0.93120393,\n",
      "       0.93611794, 0.91400491]), 'split2_test_score': array([0.8968059 , 0.90909091, 0.90909091, 0.89434889, 0.88697789,\n",
      "       0.8992629 , 0.8992629 , 0.89434889, 0.90909091, 0.91646192,\n",
      "       0.90909091, 0.90663391]), 'split3_test_score': array([0.90640394, 0.88669951, 0.88423645, 0.90147783, 0.90640394,\n",
      "       0.908867  , 0.88669951, 0.89408867, 0.91871921, 0.94334975,\n",
      "       0.908867  , 0.90640394]), 'split4_test_score': array([0.90640394, 0.91625616, 0.90147783, 0.91625616, 0.92364532,\n",
      "       0.89901478, 0.91133005, 0.89162562, 0.90640394, 0.93349754,\n",
      "       0.92364532, 0.92857143]), 'mean_test_score': array([0.90359352, 0.90064027, 0.8991576 , 0.90113894, 0.90311059,\n",
      "       0.9075223 , 0.89916365, 0.8986662 , 0.91490178, 0.93114341,\n",
      "       0.91883662, 0.90802701]), 'std_test_score': array([0.009972  , 0.01084477, 0.00900792, 0.01606407, 0.0196457 ,\n",
      "       0.00759595, 0.01467054, 0.00805971, 0.00708585, 0.00860338,\n",
      "       0.01021547, 0.01424726]), 'rank_test_score': array([ 6,  9, 11,  8,  7,  5, 10, 12,  3,  1,  2,  4], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "##Grid Search##\n",
    "clf1 = GridSearchCV(pipe_1, param_grid1)\n",
    "clf1 = clf1.fit(X_train_iso, y_train_iso)\n",
    "\n",
    "print(clf1.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dtc__max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "print(clf1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       431\n",
      "           1       0.94      0.91      0.93       441\n",
      "\n",
      "    accuracy                           0.93       872\n",
      "   macro avg       0.93      0.93      0.93       872\n",
      "weighted avg       0.93      0.93      0.93       872\n",
      "\n",
      "Overall model accuracy: 0.7109711634073583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unbiased evaluation\n",
    "# ----------------------------------\n",
    "\n",
    "y_pred1 = clf1.predict(X_test_iso)\n",
    "pd.DataFrame(confusion_matrix(y_test_iso, y_pred1))\n",
    "\n",
    "print(classification_report(y_test_iso, y_pred1))\n",
    "\n",
    "print('Overall model accuracy: {}\\n'.format(r2_score(y_test_iso, \n",
    "                                                     (clf1.predict(X_test_iso)))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iso_scores = cross_val_score(estimator = iso_model, X = X_iso, y = y_iso)\n",
    "#print(iso_scores)\n",
    "#print(\"Mean CV score w/ IsolationForest Model:\", np.mean(iso_scores))\n",
    "#print('Overall model accuracy: {}\\n'.format(r2_score(y_test_iso, (iso_model.predict(X_test_iso)))))\n",
    "\n",
    "#iso_predictions = iso_model.predict(X_test_iso)\n",
    "#print('Mean Absolute Error: {}\\n'.mean_absolute_error(y_test_iso, iso_predictions))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Optimal hyperparameters and performance resulting from Pipeline #1.</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max depth determined for the DecisisonTreeClassifier is 4. The model overall works well at about 71% accuracy, \n",
    "but could be improved upon. This still leaves about 30% that can possibly have incorrect outcomes as a result of the \n",
    "\"lowest\" performing model. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline #2\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of outliers = 66\n"
     ]
    }
   ],
   "source": [
    "# Anomaly detection \n",
    "# ----------------------------------\n",
    "one_class_svm = OneClassSVM(kernel = 'rbf', nu = 0.01).fit(X_train)\n",
    "oc_outliers = one_class_svm.fit_predict(X_train) == -1\n",
    "print(f\"Num of outliers = {np.sum(oc_outliers)}\")\n",
    "\n",
    "\n",
    "X_one_class = X_train[~oc_outliers]\n",
    "y_one_class = y_train[~oc_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oc, X_test_oc, y_train_oc, y_test_oc = train_test_split(X_one_class, \n",
    "                                                                y_one_class, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2046, 20)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_oc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00496159, 0.00544186, 0.00612664, 0.0396759 , 0.05397038,\n",
      "       0.02362671, 0.00624399, 0.00552759, 0.00521464]), 'std_fit_time': array([3.41842779e-04, 2.44717057e-04, 6.84344024e-04, 3.95429497e-02,\n",
      "       3.73559485e-02, 3.08306123e-02, 1.94167095e-04, 7.81752089e-05,\n",
      "       5.61641306e-05]), 'mean_score_time': array([0.00049024, 0.00051622, 0.00051265, 0.00071735, 0.00073428,\n",
      "       0.00065441, 0.00050282, 0.00047607, 0.00047994]), 'std_score_time': array([1.90325536e-05, 2.56063774e-05, 1.99306524e-05, 1.11419958e-04,\n",
      "       3.87127171e-05, 8.74246047e-05, 3.18604306e-05, 2.05756201e-05,\n",
      "       2.44538906e-05]), 'param_KBest__k': masked_array(data=[3, 5, 7, 10, 12, --, --, --, --],\n",
      "             mask=[False, False, False, False, False,  True,  True,  True,\n",
      "                    True],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_lr__C': masked_array(data=[--, --, --, --, --, 5.960464477539063e-08,\n",
      "                   9.536743164062494e-07, 1.5258789062499981e-05,\n",
      "                   0.000244140625],\n",
      "             mask=[ True,  True,  True,  True,  True, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'KBest__k': 3}, {'KBest__k': 5}, {'KBest__k': 7}, {'KBest__k': 10}, {'KBest__k': 12}, {'lr__C': 5.960464477539063e-08}, {'lr__C': 9.536743164062494e-07}, {'lr__C': 1.5258789062499981e-05}, {'lr__C': 0.000244140625}], 'split0_test_score': array([0.88292683, 0.88292683, 0.88292683, 0.88780488, 0.8804878 ,\n",
      "       0.51219512, 0.51219512, 0.55609756, 0.8804878 ]), 'split1_test_score': array([0.92176039, 0.92420538, 0.92420538, 0.92420538, 0.92420538,\n",
      "       0.51100244, 0.51100244, 0.55012225, 0.92420538]), 'split2_test_score': array([0.92176039, 0.91687042, 0.91442543, 0.90464548, 0.90953545,\n",
      "       0.51100244, 0.51100244, 0.5403423 , 0.91687042]), 'split3_test_score': array([0.92176039, 0.92176039, 0.92420538, 0.91687042, 0.92176039,\n",
      "       0.51100244, 0.51100244, 0.54767726, 0.92420538]), 'split4_test_score': array([0.91442543, 0.91442543, 0.9193154 , 0.9193154 , 0.91198044,\n",
      "       0.51100244, 0.51100244, 0.54278729, 0.91442543]), 'mean_test_score': array([0.91252669, 0.91203769, 0.91301568, 0.91056831, 0.90959389,\n",
      "       0.51124098, 0.51124098, 0.54740533, 0.91203888]), 'std_test_score': array([0.01507011, 0.0149605 , 0.01547535, 0.01308015, 0.0155845 ,\n",
      "       0.00047707, 0.00047707, 0.0055538 , 0.01625151]), 'rank_test_score': array([2, 4, 1, 5, 6, 8, 8, 7, 3], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "# Feature selection and classification pipeline with grid search\n",
    "# ----------------------------------\n",
    "##Feature Selection - KBest##\n",
    "\n",
    "#def mutual_info_session(): \n",
    "#    selector = SelectKBest(chi2, k = 5)\n",
    "#    selector.fit(X_train_oc, y_train_oc)\n",
    "#    print(selector.get_support(True))\n",
    "#    model11 = GausssianNB()\n",
    "#    model.fit(selector.transform(X_train_oc), y_train_oc)\n",
    "#    return model.score(selector.transform(X_test_oc), y_test_oc)\n",
    "\n",
    "#mutual_info_session()\n",
    "\n",
    "\n",
    "#pipeline\n",
    "\n",
    "pipe_2 = Pipeline([('KBest', SelectKBest(f_classif, k = 5)),\n",
    "                  ('lr', LogisticRegression())])\n",
    "\n",
    "#pipe_2 = Pipeline([('KBest', SelectKBest(mutual_info_session(), k = 5)),\n",
    "#                  ('lr', LogisticRegression())])\n",
    "\n",
    "#hyperparams\n",
    "\n",
    "param_grid2 = [{'KBest__k': [3, 5, 7, 10, 12]},\n",
    "                {'lr__C': np.logspace(-8, -4, 4, 6, 8)}]\n",
    "                \n",
    "\n",
    "\n",
    "#gridsearch\n",
    "\n",
    "clf2 = GridSearchCV(pipe_2, param_grid2)\n",
    "clf2 = clf2.fit(X_train_oc, y_train_oc)\n",
    "\n",
    "print(clf2.cv_results_)\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KBest__k': 7}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       421\n",
      "           1       0.90      0.90      0.90       456\n",
      "\n",
      "    accuracy                           0.89       877\n",
      "   macro avg       0.89      0.89      0.89       877\n",
      "weighted avg       0.89      0.89      0.89       877\n",
      "\n",
      "Overall model accuracy: 0.5705817393840896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unbiased evaluation\n",
    "# ----------------------------------\n",
    "print(clf2.best_params_)\n",
    "\n",
    "y_pred2 = clf2.predict(X_test_oc)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test_oc, y_pred2))\n",
    "\n",
    "print(classification_report(y_test_oc, y_pred2))\n",
    "\n",
    "print('Overall model accuracy: {}\\n'.format(r2_score(y_test_oc, \n",
    "                                                     (clf2.predict(X_test_oc)))))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Optimal hyperparameters and performance resulting Pipeline #2.</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal hyperparameters for the bets number of features is 3 when compared to earlier models using more options. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of outliers = 2\n"
     ]
    }
   ],
   "source": [
    "# Anomaly detection \n",
    "# ----------------------------------\n",
    "#LocalOutlierFactor\n",
    "lof = LocalOutlierFactor(n_neighbors = 5).fit(X_train)\n",
    "lof_outliers = lof.fit_predict(X_train) == -1\n",
    "print(f\"Num of outliers = {np.sum(lof_outliers)}\")\n",
    "\n",
    "X_lof = X_train[~lof_outliers]\n",
    "y_lof = y_train[~lof_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lof, X_test_lof, y_train_lof, y_test_lof = train_test_split(X_lof, y_lof, test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2090, 20)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection and classification pipeline with grid search\n",
    "# ----------------------------------\n",
    "#LinearSVC\n",
    "#from sklearn.svm import LinearSVC\n",
    "\n",
    "n_components = 5\n",
    "\n",
    "#pipe_3 = Pipeline({'fa', FactorAnalysis(n_components = n_components, random_state = 0)}, \n",
    "#                  {'lsvc', LinearSVC(random_state = 0)})\n",
    "\n",
    "pipe_3 = Pipeline([('fa', FactorAnalysis(n_components = n_components, random_state = 0)), \n",
    "                  ('SVC', SVC())])\n",
    "\n",
    "param_grid3 = [{'fa__n_components': [3, 5, 7, 10, 12]}, \n",
    "               {'SVC__C': [1, 10, 100, 1000]}, \n",
    "               {'SVC__gamma': [0.001, 0.0001]},\n",
    "               {'SVC__kernel': ['rbf', 'linear']}]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.75502992, 1.67042456, 1.96780086, 1.96705608, 1.40234399,\n",
      "       1.04546828, 1.08716216, 1.03823357, 1.40704947, 1.18395143,\n",
      "       1.10017757, 1.10930657, 1.0889781 ]), 'std_fit_time': array([0.08929708, 0.21981655, 0.92241111, 0.12682547, 0.15983107,\n",
      "       0.10048561, 0.07002614, 0.16492182, 0.34456113, 0.3347494 ,\n",
      "       0.13339451, 0.01902695, 0.06736827]), 'mean_score_time': array([0.0398067 , 0.01096716, 0.01158414, 0.01375289, 0.01587076,\n",
      "       0.01014738, 0.00859952, 0.01084933, 0.00821271, 0.02648463,\n",
      "       0.04518042, 0.01228862, 0.00593596]), 'std_score_time': array([0.0381594 , 0.00177215, 0.0007319 , 0.00056095, 0.00086173,\n",
      "       0.00056497, 0.0005205 , 0.00376312, 0.00076044, 0.00043212,\n",
      "       0.01133899, 0.00345337, 0.00111269]), 'param_fa__n_components': masked_array(data=[3, 5, 7, 10, 12, --, --, --, --, --, --, --, --],\n",
      "             mask=[False, False, False, False, False,  True,  True,  True,\n",
      "                    True,  True,  True,  True,  True],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVC__C': masked_array(data=[--, --, --, --, --, 1, 10, 100, 1000, --, --, --, --],\n",
      "             mask=[ True,  True,  True,  True,  True, False, False, False,\n",
      "                   False,  True,  True,  True,  True],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVC__gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, 0.001, 0.0001, --,\n",
      "                   --],\n",
      "             mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
      "                    True, False, False,  True,  True],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_SVC__kernel': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, 'rbf',\n",
      "                   'linear'],\n",
      "             mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
      "                    True,  True,  True, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'fa__n_components': 3}, {'fa__n_components': 5}, {'fa__n_components': 7}, {'fa__n_components': 10}, {'fa__n_components': 12}, {'SVC__C': 1}, {'SVC__C': 10}, {'SVC__C': 100}, {'SVC__C': 1000}, {'SVC__gamma': 0.001}, {'SVC__gamma': 0.0001}, {'SVC__kernel': 'rbf'}, {'SVC__kernel': 'linear'}], 'split0_test_score': array([0.90430622, 0.89952153, 0.89952153, 0.89712919, 0.88995215,\n",
      "       0.89952153, 0.89952153, 0.89712919, 0.88755981, 0.86124402,\n",
      "       0.50956938, 0.89952153, 0.87799043]), 'split1_test_score': array([0.94497608, 0.94258373, 0.94258373, 0.94019139, 0.94019139,\n",
      "       0.94258373, 0.94736842, 0.93779904, 0.91866029, 0.93301435,\n",
      "       0.51196172, 0.94258373, 0.93301435]), 'split2_test_score': array([0.9569378 , 0.95215311, 0.95215311, 0.93301435, 0.9354067 ,\n",
      "       0.95215311, 0.9569378 , 0.95215311, 0.93062201, 0.90430622,\n",
      "       0.51435407, 0.95215311, 0.9138756 ]), 'split3_test_score': array([0.93779904, 0.93779904, 0.93062201, 0.92583732, 0.92344498,\n",
      "       0.93779904, 0.94258373, 0.93301435, 0.9138756 , 0.89952153,\n",
      "       0.51913876, 0.93779904, 0.91148325]), 'split4_test_score': array([0.94019139, 0.93779904, 0.93301435, 0.92822967, 0.92583732,\n",
      "       0.93779904, 0.94497608, 0.94497608, 0.93062201, 0.90430622,\n",
      "       0.51674641, 0.93779904, 0.90430622]), 'mean_test_score': array([0.93684211, 0.93397129, 0.93157895, 0.92488038, 0.92296651,\n",
      "       0.93397129, 0.93827751, 0.93301435, 0.91626794, 0.90047847,\n",
      "       0.51435407, 0.93397129, 0.90813397]), 'std_test_score': array([0.01755401, 0.01800468, 0.01774855, 0.01471632, 0.0176061 ,\n",
      "       0.01800468, 0.01998145, 0.01907885, 0.01579672, 0.0229266 ,\n",
      "       0.00338329, 0.01800468, 0.01781293]), 'rank_test_score': array([ 2,  3,  7,  8,  9,  3,  1,  6, 10, 12, 13,  3, 11], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "clf3 = GridSearchCV(pipe_3, param_grid3)\n",
    "clf3 = clf3.fit(X_train_lof, y_train_lof)\n",
    "\n",
    "print(clf3.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fa__n_components</th>\n",
       "      <th>SVC__C</th>\n",
       "      <th>SVC__gamma</th>\n",
       "      <th>SVC__kernel</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.936842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.931579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.924880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.922967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.933971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.908134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fa__n_components  SVC__C  SVC__gamma SVC__kernel  Accuracy\n",
       "0                3.0     NaN         NaN         NaN  0.936842\n",
       "1                5.0     NaN         NaN         NaN  0.933971\n",
       "2                7.0     NaN         NaN         NaN  0.931579\n",
       "3               10.0     NaN         NaN         NaN  0.924880\n",
       "4               12.0     NaN         NaN         NaN  0.922967\n",
       "5                NaN     1.0         NaN         NaN  0.933971\n",
       "6                NaN    10.0         NaN         NaN  0.938278\n",
       "7                NaN   100.0         NaN         NaN  0.933014\n",
       "8                NaN  1000.0         NaN         NaN  0.916268\n",
       "9                NaN     NaN      0.0010         NaN  0.900478\n",
       "10               NaN     NaN      0.0001         NaN  0.514354\n",
       "11               NaN     NaN         NaN         rbf  0.933971\n",
       "12               NaN     NaN         NaN      linear  0.908134"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.concat([pd.DataFrame(clf3.cv_results_[\"params\"]),pd.DataFrame(clf3.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Test Score</th>\n",
       "      <th>Std Test Score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'SVC__C': 10}</td>\n",
       "      <td>0.938278</td>\n",
       "      <td>0.019981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'fa__n_components': 3}</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'fa__n_components': 5}</td>\n",
       "      <td>0.933971</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'SVC__C': 1}</td>\n",
       "      <td>0.933971</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'SVC__kernel': 'rbf'}</td>\n",
       "      <td>0.933971</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'SVC__C': 100}</td>\n",
       "      <td>0.933014</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'fa__n_components': 7}</td>\n",
       "      <td>0.931579</td>\n",
       "      <td>0.017749</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'fa__n_components': 10}</td>\n",
       "      <td>0.924880</td>\n",
       "      <td>0.014716</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'fa__n_components': 12}</td>\n",
       "      <td>0.922967</td>\n",
       "      <td>0.017606</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'SVC__C': 1000}</td>\n",
       "      <td>0.916268</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'SVC__kernel': 'linear'}</td>\n",
       "      <td>0.908134</td>\n",
       "      <td>0.017813</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'SVC__gamma': 0.001}</td>\n",
       "      <td>0.900478</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'SVC__gamma': 0.0001}</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Mean Test Score  Std Test Score  Rank\n",
       "6              {'SVC__C': 10}         0.938278        0.019981     1\n",
       "0     {'fa__n_components': 3}         0.936842        0.017554     2\n",
       "1     {'fa__n_components': 5}         0.933971        0.018005     3\n",
       "5               {'SVC__C': 1}         0.933971        0.018005     3\n",
       "11     {'SVC__kernel': 'rbf'}         0.933971        0.018005     3\n",
       "7             {'SVC__C': 100}         0.933014        0.019079     6\n",
       "2     {'fa__n_components': 7}         0.931579        0.017749     7\n",
       "3    {'fa__n_components': 10}         0.924880        0.014716     8\n",
       "4    {'fa__n_components': 12}         0.922967        0.017606     9\n",
       "8            {'SVC__C': 1000}         0.916268        0.015797    10\n",
       "12  {'SVC__kernel': 'linear'}         0.908134        0.017813    11\n",
       "9       {'SVC__gamma': 0.001}         0.900478        0.022927    12\n",
       "10     {'SVC__gamma': 0.0001}         0.514354        0.003383    13"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rank_tbl = pd.DataFrame(\n",
    "    {\n",
    "        'Model': clf3.cv_results_['params'],\n",
    "        'Mean Test Score': clf3.cv_results_['mean_test_score'],\n",
    "        'Std Test Score': clf3.cv_results_['std_test_score'],\n",
    "        'Rank': clf3.cv_results_['rank_test_score']\n",
    "    }\n",
    ")\n",
    "\n",
    "rank_tbl.sort_values('Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVC__C': 10}\n",
      "     0    1\n",
      "0  423   14\n",
      "1   35  425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95       437\n",
      "           1       0.97      0.92      0.95       460\n",
      "\n",
      "    accuracy                           0.95       897\n",
      "   macro avg       0.95      0.95      0.95       897\n",
      "weighted avg       0.95      0.95      0.95       897\n",
      "\n",
      "Overall model accuracy: 0.7813501144164761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unbiased evaluation\n",
    "# ----------------------------------\n",
    "print(clf3.best_params_)\n",
    "\n",
    "y_pred3 = clf3.predict(X_test_lof)\n",
    "\n",
    "print(pd.DataFrame(confusion_matrix(y_test_lof, y_pred3)))\n",
    "\n",
    "print(classification_report(y_test_lof, y_pred3))\n",
    "\n",
    "print('Overall model accuracy: {}\\n'.format(r2_score(y_test_lof, \n",
    "                                                     (clf3.predict(X_test_lof)))))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Optimal hyperparameters and performance resulting from Pipeline #3.</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best performing model, with 83% accuracy and the most optimal hyperparameters invole setting the FactorAnalysis n_components to 3. Although this is the best model, it could definitely be skewed because the anomaly detection method used (LocalOutlierFactor) found 0 outliers. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall\n",
    "The anomaly detection methods varied quite often on models 1 / 2 when compared to model 3. This likely attributed to model 3 appearing to perform better than the others, however because Random Up Sampling was performed in Part I of this assignment, it could also contribute to the lower number of outliers overall (for all models). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sampledata-Part2-V1.pkl']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pickle the required pipeline/models\n",
    "joblib.dump(pipe_3, 'sampledata-Part2-V1.pkl') \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the End. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
